{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"name":"Class Aug Classifier - Images.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZOniO02BnoOp","executionInfo":{"status":"ok","timestamp":1654173780410,"user_tz":-300,"elapsed":3181,"user":{"displayName":"Mohammad Areeb Siddiqui","userId":"14081878860323978183"}},"outputId":"3c000191-ed2d-44cc-e537-f79a8cd4aad2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"ZOniO02BnoOp","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Hl7tE5znvNz","executionInfo":{"status":"ok","timestamp":1654173780411,"user_tz":-300,"elapsed":8,"user":{"displayName":"Mohammad Areeb Siddiqui","userId":"14081878860323978183"}},"outputId":"74605219-9d4d-4986-847f-bea4932dc7b1"},"source":["cd \"/content/drive/MyDrive/ClassAug Work\""],"id":"0Hl7tE5znvNz","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/12PFZZk88jXqRuPPPvsCgycke0gd7aQBI/ClassAug Work\n"]}]},{"cell_type":"code","metadata":{"id":"d1f12922"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from itertools import combinations\n","from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, average_precision_score, precision_recall_curve, auc, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.decomposition import PCA"],"id":"d1f12922","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fec4836"},"source":["data = None\n","with open('./embeddings/cifar10_resnet50_embeddings.pkl', 'rb') as f:\n","    data = pickle.load(f)\n","    \n","embs = data['embs']\n","labels = data['labels']"],"id":"8fec4836","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ca8255b"},"source":["label_mapping_reverse = {\n","  0: \"airplane\",\n","  1: \"automobile\",\n","  2: \"bird\",\n","  3: \"cat\",\n","  4: \"deer\",\n","  5: \"dog\",\n","  6: \"frog\",\n","  7: \"horse\",\n","  8: \"ship\",\n","  9: \"truck\"\n","}\n","label_mapping = {}\n","for k, v in label_mapping_reverse.items():\n","    label_mapping[v] = k"],"id":"7ca8255b","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"401d8428"},"source":["classes = list(label_mapping.keys())\n","\n","adhoc_classes = list(combinations(classes, 2))\n","adhoc_classes = ['|'.join(comb) for comb in adhoc_classes]\n","\n","all_classes = classes\n","all_classes.extend(adhoc_classes)\n","\n","for i, c in enumerate(all_classes):\n","    if c not in label_mapping:\n","        label_mapping[c] = i\n","\n","for i, c in enumerate(all_classes):\n","    if i not in label_mapping_reverse:\n","        label_mapping_reverse[i] = c"],"id":"401d8428","execution_count":null,"outputs":[]},{"cell_type":"code","source":["crs = np.array([tuple(map(lambda x: int(label_mapping[x]), adhoc_class.split(\"|\"))) for adhoc_class in adhoc_classes])"],"metadata":{"id":"Lca7zU0UZbsu"},"id":"Lca7zU0UZbsu","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fceb8fd6","executionInfo":{"status":"ok","timestamp":1654173794236,"user_tz":-300,"elapsed":559,"user":{"displayName":"Mohammad Areeb Siddiqui","userId":"14081878860323978183"}},"outputId":"071c15cf-0dec-4a60-cb11-e64894028ddd"},"source":["x_train, x_test, y_train, y_test = train_test_split(embs, labels, test_size=0.30, random_state=43, stratify=labels)\n","print(x_train.shape)\n","print(x_test.shape)\n","print(y_train.shape)\n","print(y_test.shape)"],"id":"fceb8fd6","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(42000, 2048)\n","(18000, 2048)\n","(42000, 1)\n","(18000, 1)\n"]}]},{"cell_type":"code","metadata":{"id":"586f7cbe"},"source":["class DataGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, embs, labels, batch_size=64, dim=2048, n_classes=55, shuffle=True):\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.embs = embs\n","        self.n_classes = n_classes\n","        self.labels = tf.keras.utils.to_categorical(labels, num_classes=self.n_classes, dtype=np.int16)\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        return int(np.floor(self.embs.shape[0] / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        X, y = self.__data_generation(indexes)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(self.embs.shape[0])\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, indexes):        \n","        X = self.embs[indexes]\n","        y = self.labels[indexes]\n","\n","        p = np.random.permutation(np.arange(X.shape[0]))\n","        X = X[p]\n","        y = y[p]\n","        \n","        return X, y"],"id":"586f7cbe","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"994f2888"},"source":["class AdhocDataGenerator(keras.utils.Sequence):\n","    def __init__(self, embs, labels, label_mapping, label_mapping_reverse, batch_size=64, adhoc_batch_size=192, dim=2048, n_classes=10, n_adhoc_classes=45, crs=[], shuffle=True):\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.adhoc_batch_size = adhoc_batch_size\n","        self.total_batch_size = batch_size + adhoc_batch_size\n","        self.label_mapping = label_mapping\n","        self.label_mapping_reverse = label_mapping_reverse\n","        self.embs = embs\n","        self.n_classes = n_classes\n","        self.n_adhoc_classes = n_adhoc_classes\n","        self.crs = crs\n","        self.total_classes = n_classes + n_adhoc_classes\n","        self.one_cold_labels = np.squeeze(labels)\n","        self.labels = keras.utils.to_categorical(labels, num_classes=self.total_classes, dtype=np.int16)\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","        self.__generate_confused_examples()\n","       \n","    def __generate_confused_examples(self):\n","        idx = np.random.choice(len(self.crs), size=self.embs.shape[0])\n","        class1, class2 = self.crs[idx][:,0], self.crs[idx][:,1]\n","        confused_examples = np.zeros((self.embs.shape[0], 2, self.dim))\n","        confused_examples_labels = np.zeros((self.embs.shape[0], self.total_classes))\n","        class_examples = {}\n","        i = 0\n","        for c1, c2 in zip(class1, class2):\n","            if i % 10000 == 0:\n","                print(f'Examples #{i}/{class1.shape[0]}')\n","            if c1 not in class_examples:\n","                class_examples[c1] = self.embs[self.one_cold_labels == c1]\n","            if c2 not in class_examples:\n","                class_examples[c2] = self.embs[self.one_cold_labels == c2]\n","            \n","            confused_examples[i][0] = self.__get_random_choice(class_examples[c1]) + np.random.normal(0.5, 1, self.dim)\n","            confused_examples[i][1] = self.__get_random_choice(class_examples[c2]) + np.random.normal(0.5, 1, self.dim)\n","            \n","            confused_examples_labels[i] = keras.utils.to_categorical(\n","                self.label_mapping[\n","                    self.label_mapping_reverse[c1] + '|' + self.label_mapping_reverse[c2]\n","                ]\n","            , num_classes=self.total_classes)\n","            \n","            i += 1\n","        class_examples = {}\n","        lamda = np.random.uniform(0.4, 0.6, size=self.embs.shape[0]).reshape(-1, 1)\n","        \n","        self.confused_examples = (lamda*confused_examples[:,0]) + ((1-lamda)*confused_examples[:,1])\n","        self.confused_examples_labels = confused_examples_labels\n","\n","    def __len__(self):\n","        return int(np.floor(self.embs.shape[0] / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        X, y = self.__data_generation(indexes)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(self.embs.shape[0])\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __get_random_choice(self, arr):\n","        idx = np.random.choice(len(arr))\n","        return arr[idx]\n","            \n","    def __data_generation(self, indexes):\n","        batch_x = self.embs[indexes]\n","        batch_y = self.labels[indexes]\n","        \n","        X = np.zeros(([self.batch_size+self.adhoc_batch_size, self.dim]), dtype=np.float32)\n","        y = np.zeros(([self.batch_size+self.adhoc_batch_size, self.total_classes]), dtype=np.int16)\n","        \n","        X[:self.batch_size, :] = self.embs[indexes]\n","        y[:self.batch_size, :] = self.labels[indexes]\n","        \n","        idx = np.random.choice(self.confused_examples.shape[0], size=self.adhoc_batch_size)\n","        X[self.batch_size:, :] = self.confused_examples[idx]\n","        y[self.batch_size:, :] = self.confused_examples_labels[idx]\n","        \n","        p = np.random.permutation(np.arange(X.shape[0]))\n","        X = X[p]\n","        y = y[p]\n","        \n","        return X, y"],"id":"994f2888","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d8159036","executionInfo":{"status":"ok","timestamp":1654173806474,"user_tz":-300,"elapsed":12241,"user":{"displayName":"Mohammad Areeb Siddiqui","userId":"14081878860323978183"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3c8e4ea3-7746-4335-f898-c7a2e8693ab8"},"source":["training_generator = AdhocDataGenerator(x_train, y_train, label_mapping, label_mapping_reverse, crs=crs)\n","validation_generator = DataGenerator(x_test, y_test)"],"id":"d8159036","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Examples #0/42000\n","Examples #10000/42000\n","Examples #20000/42000\n","Examples #30000/42000\n","Examples #40000/42000\n"]}]},{"cell_type":"code","metadata":{"id":"20629b76"},"source":["keras.backend.clear_session()\n","model = keras.models.Sequential()\n","model.add(keras.layers.Dense(1024, activity_regularizer='l2', activation='relu', input_shape=(2048,)))\n","model.add(keras.layers.Dense(10+45, activity_regularizer='l2', activation='relu'))\n","model.add(keras.layers.Softmax())"],"id":"20629b76","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4b7232a","executionInfo":{"status":"ok","timestamp":1654173818631,"user_tz":-300,"elapsed":347,"user":{"displayName":"Mohammad Areeb Siddiqui","userId":"14081878860323978183"}},"outputId":"7d0217a0-e141-4790-8781-d366826e8003"},"source":["# model.load_weights('./models/')\n","model.summary()"],"id":"d4b7232a","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 1024)              2098176   \n","                                                                 \n"," dense_1 (Dense)             (None, 55)                56375     \n","                                                                 \n"," softmax (Softmax)           (None, 55)                0         \n","                                                                 \n","=================================================================\n","Total params: 2,154,551\n","Trainable params: 2,154,551\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"490db929"},"source":["checkpoint_filepath = './checkpoints/classaug_cifar10_best_{val_accuracy:.2f}_updated_generator.h5'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","filepath=checkpoint_filepath,\n","save_weights_only=True,\n","monitor='val_accuracy',\n","mode='max',\n","save_best_only=True)\n","model.compile(\n","    optimizer=keras.optimizers.SGD(), \n","    loss='categorical_crossentropy', \n","    metrics=['accuracy']\n",")"],"id":"490db929","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"f79f2814","scrolled":true,"outputId":"e4c7536b-f1c6-40fd-cdb5-69d5d3f3e2d1","executionInfo":{"status":"error","timestamp":1654177903401,"user_tz":-300,"elapsed":3353048,"user":{"displayName":"Mohammad Areeb Siddiqui","userId":"14081878860323978183"}}},"source":["history=model.fit(training_generator, validation_data=validation_generator, epochs=1000, callbacks=[model_checkpoint_callback])"],"id":"f79f2814","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","656/656 [==============================] - 9s 9ms/step - loss: 3.9252 - accuracy: 0.1479 - val_loss: 2.5397 - val_accuracy: 0.7642\n","Epoch 2/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 3.5722 - accuracy: 0.2061 - val_loss: 1.9979 - val_accuracy: 0.8310\n","Epoch 3/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 3.4628 - accuracy: 0.2220 - val_loss: 1.7710 - val_accuracy: 0.8550\n","Epoch 4/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 3.3823 - accuracy: 0.2490 - val_loss: 1.6610 - val_accuracy: 0.8690\n","Epoch 5/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 3.2855 - accuracy: 0.2863 - val_loss: 1.5957 - val_accuracy: 0.8775\n","Epoch 6/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 3.1837 - accuracy: 0.3182 - val_loss: 1.5424 - val_accuracy: 0.8822\n","Epoch 7/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 3.0901 - accuracy: 0.3485 - val_loss: 1.4952 - val_accuracy: 0.8863\n","Epoch 8/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 3.0018 - accuracy: 0.3948 - val_loss: 1.4620 - val_accuracy: 0.8885\n","Epoch 9/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 2.9095 - accuracy: 0.4547 - val_loss: 1.4350 - val_accuracy: 0.8914\n","Epoch 10/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 2.8115 - accuracy: 0.5144 - val_loss: 1.4194 - val_accuracy: 0.8952\n","Epoch 11/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 2.7127 - accuracy: 0.5649 - val_loss: 1.3933 - val_accuracy: 0.8949\n","Epoch 12/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 2.6197 - accuracy: 0.6107 - val_loss: 1.3702 - val_accuracy: 0.8975\n","Epoch 13/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 2.5267 - accuracy: 0.6500 - val_loss: 1.3511 - val_accuracy: 0.8991\n","Epoch 14/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 2.4425 - accuracy: 0.6767 - val_loss: 1.3341 - val_accuracy: 0.9004\n","Epoch 15/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 2.3694 - accuracy: 0.6995 - val_loss: 1.3176 - val_accuracy: 0.9015\n","Epoch 16/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 2.3077 - accuracy: 0.7121 - val_loss: 1.3039 - val_accuracy: 0.9027\n","Epoch 17/1000\n","656/656 [==============================] - 5s 7ms/step - loss: 2.2523 - accuracy: 0.7235 - val_loss: 1.2831 - val_accuracy: 0.9037\n","Epoch 18/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 2.2068 - accuracy: 0.7319 - val_loss: 1.2767 - val_accuracy: 0.9042\n","Epoch 19/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 2.1708 - accuracy: 0.7367 - val_loss: 1.2628 - val_accuracy: 0.9044\n","Epoch 20/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 2.1305 - accuracy: 0.7433 - val_loss: 1.2495 - val_accuracy: 0.9046\n","Epoch 21/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 2.1103 - accuracy: 0.7439 - val_loss: 1.2352 - val_accuracy: 0.9062\n","Epoch 22/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 2.0829 - accuracy: 0.7457 - val_loss: 1.2254 - val_accuracy: 0.9070\n","Epoch 23/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 2.0588 - accuracy: 0.7497 - val_loss: 1.2244 - val_accuracy: 0.9061\n","Epoch 24/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 2.0425 - accuracy: 0.7482 - val_loss: 1.2130 - val_accuracy: 0.9086\n","Epoch 25/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 2.0254 - accuracy: 0.7494 - val_loss: 1.2031 - val_accuracy: 0.9085\n","Epoch 26/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 2.0097 - accuracy: 0.7514 - val_loss: 1.2041 - val_accuracy: 0.9086\n","Epoch 27/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.9969 - accuracy: 0.7524 - val_loss: 1.1919 - val_accuracy: 0.9085\n","Epoch 28/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.9867 - accuracy: 0.7516 - val_loss: 1.1842 - val_accuracy: 0.9094\n","Epoch 29/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.9706 - accuracy: 0.7537 - val_loss: 1.1766 - val_accuracy: 0.9095\n","Epoch 30/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.9660 - accuracy: 0.7529 - val_loss: 1.1771 - val_accuracy: 0.9092\n","Epoch 31/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.9515 - accuracy: 0.7548 - val_loss: 1.1740 - val_accuracy: 0.9100\n","Epoch 32/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.9412 - accuracy: 0.7570 - val_loss: 1.1764 - val_accuracy: 0.9078\n","Epoch 33/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.9347 - accuracy: 0.7554 - val_loss: 1.1674 - val_accuracy: 0.9110\n","Epoch 34/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.9212 - accuracy: 0.7596 - val_loss: 1.1601 - val_accuracy: 0.9109\n","Epoch 35/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.9103 - accuracy: 0.7614 - val_loss: 1.1536 - val_accuracy: 0.9110\n","Epoch 36/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.9054 - accuracy: 0.7613 - val_loss: 1.1521 - val_accuracy: 0.9113\n","Epoch 37/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.8954 - accuracy: 0.7611 - val_loss: 1.1434 - val_accuracy: 0.9123\n","Epoch 38/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.8942 - accuracy: 0.7618 - val_loss: 1.1446 - val_accuracy: 0.9119\n","Epoch 39/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.8833 - accuracy: 0.7625 - val_loss: 1.1368 - val_accuracy: 0.9122\n","Epoch 40/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.8737 - accuracy: 0.7651 - val_loss: 1.1444 - val_accuracy: 0.9110\n","Epoch 41/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.8684 - accuracy: 0.7657 - val_loss: 1.1410 - val_accuracy: 0.9126\n","Epoch 42/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.8566 - accuracy: 0.7685 - val_loss: 1.1384 - val_accuracy: 0.9110\n","Epoch 43/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.8520 - accuracy: 0.7692 - val_loss: 1.1329 - val_accuracy: 0.9128\n","Epoch 44/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.8504 - accuracy: 0.7681 - val_loss: 1.1318 - val_accuracy: 0.9144\n","Epoch 45/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.8489 - accuracy: 0.7677 - val_loss: 1.1235 - val_accuracy: 0.9135\n","Epoch 46/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.8267 - accuracy: 0.7746 - val_loss: 1.1290 - val_accuracy: 0.9138\n","Epoch 47/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.8316 - accuracy: 0.7706 - val_loss: 1.1147 - val_accuracy: 0.9143\n","Epoch 48/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 1.8275 - accuracy: 0.7715 - val_loss: 1.1168 - val_accuracy: 0.9135\n","Epoch 49/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.8228 - accuracy: 0.7720 - val_loss: 1.1209 - val_accuracy: 0.9135\n","Epoch 50/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.8151 - accuracy: 0.7733 - val_loss: 1.1136 - val_accuracy: 0.9146\n","Epoch 51/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.8092 - accuracy: 0.7754 - val_loss: 1.1115 - val_accuracy: 0.9143\n","Epoch 52/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.8118 - accuracy: 0.7735 - val_loss: 1.1127 - val_accuracy: 0.9146\n","Epoch 53/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.8010 - accuracy: 0.7760 - val_loss: 1.1090 - val_accuracy: 0.9131\n","Epoch 54/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.7963 - accuracy: 0.7764 - val_loss: 1.1046 - val_accuracy: 0.9151\n","Epoch 55/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.7914 - accuracy: 0.7775 - val_loss: 1.1029 - val_accuracy: 0.9148\n","Epoch 56/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.7813 - accuracy: 0.7809 - val_loss: 1.1016 - val_accuracy: 0.9143\n","Epoch 57/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.7843 - accuracy: 0.7797 - val_loss: 1.0991 - val_accuracy: 0.9154\n","Epoch 58/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.7734 - accuracy: 0.7823 - val_loss: 1.0933 - val_accuracy: 0.9152\n","Epoch 59/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.7735 - accuracy: 0.7821 - val_loss: 1.1000 - val_accuracy: 0.9140\n","Epoch 60/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.7681 - accuracy: 0.7835 - val_loss: 1.1027 - val_accuracy: 0.9150\n","Epoch 61/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.7651 - accuracy: 0.7833 - val_loss: 1.1022 - val_accuracy: 0.9134\n","Epoch 62/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.7585 - accuracy: 0.7856 - val_loss: 1.0972 - val_accuracy: 0.9156\n","Epoch 63/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.7581 - accuracy: 0.7842 - val_loss: 1.0978 - val_accuracy: 0.9151\n","Epoch 64/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.7532 - accuracy: 0.7851 - val_loss: 1.0887 - val_accuracy: 0.9159\n","Epoch 65/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.7466 - accuracy: 0.7875 - val_loss: 1.1004 - val_accuracy: 0.9137\n","Epoch 66/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.7406 - accuracy: 0.7899 - val_loss: 1.0894 - val_accuracy: 0.9154\n","Epoch 67/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.7421 - accuracy: 0.7883 - val_loss: 1.1000 - val_accuracy: 0.9135\n","Epoch 68/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.7351 - accuracy: 0.7896 - val_loss: 1.0921 - val_accuracy: 0.9143\n","Epoch 69/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.7262 - accuracy: 0.7932 - val_loss: 1.0918 - val_accuracy: 0.9127\n","Epoch 70/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.7316 - accuracy: 0.7903 - val_loss: 1.0919 - val_accuracy: 0.9147\n","Epoch 71/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.7156 - accuracy: 0.7947 - val_loss: 1.0843 - val_accuracy: 0.9150\n","Epoch 72/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.7232 - accuracy: 0.7919 - val_loss: 1.0826 - val_accuracy: 0.9153\n","Epoch 73/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.7106 - accuracy: 0.7963 - val_loss: 1.0807 - val_accuracy: 0.9160\n","Epoch 74/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.7103 - accuracy: 0.7948 - val_loss: 1.0922 - val_accuracy: 0.9153\n","Epoch 75/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.7081 - accuracy: 0.7949 - val_loss: 1.0880 - val_accuracy: 0.9136\n","Epoch 76/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.7016 - accuracy: 0.7975 - val_loss: 1.0879 - val_accuracy: 0.9141\n","Epoch 77/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6969 - accuracy: 0.7988 - val_loss: 1.0841 - val_accuracy: 0.9147\n","Epoch 78/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6955 - accuracy: 0.7992 - val_loss: 1.0882 - val_accuracy: 0.9143\n","Epoch 79/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6913 - accuracy: 0.8016 - val_loss: 1.0887 - val_accuracy: 0.9145\n","Epoch 80/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6888 - accuracy: 0.7998 - val_loss: 1.0860 - val_accuracy: 0.9149\n","Epoch 81/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6802 - accuracy: 0.8032 - val_loss: 1.0855 - val_accuracy: 0.9140\n","Epoch 82/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6796 - accuracy: 0.8014 - val_loss: 1.0881 - val_accuracy: 0.9149\n","Epoch 83/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6764 - accuracy: 0.8031 - val_loss: 1.0886 - val_accuracy: 0.9153\n","Epoch 84/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6711 - accuracy: 0.8049 - val_loss: 1.0885 - val_accuracy: 0.9140\n","Epoch 85/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6656 - accuracy: 0.8063 - val_loss: 1.0848 - val_accuracy: 0.9153\n","Epoch 86/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6686 - accuracy: 0.8036 - val_loss: 1.0837 - val_accuracy: 0.9152\n","Epoch 87/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6581 - accuracy: 0.8083 - val_loss: 1.0863 - val_accuracy: 0.9146\n","Epoch 88/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6535 - accuracy: 0.8106 - val_loss: 1.0770 - val_accuracy: 0.9155\n","Epoch 89/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6523 - accuracy: 0.8096 - val_loss: 1.0766 - val_accuracy: 0.9149\n","Epoch 90/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6482 - accuracy: 0.8099 - val_loss: 1.0753 - val_accuracy: 0.9148\n","Epoch 91/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6445 - accuracy: 0.8105 - val_loss: 1.0713 - val_accuracy: 0.9162\n","Epoch 92/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6369 - accuracy: 0.8128 - val_loss: 1.0855 - val_accuracy: 0.9145\n","Epoch 93/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6356 - accuracy: 0.8129 - val_loss: 1.0742 - val_accuracy: 0.9148\n","Epoch 94/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.6324 - accuracy: 0.8141 - val_loss: 1.0795 - val_accuracy: 0.9143\n","Epoch 95/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.6307 - accuracy: 0.8135 - val_loss: 1.0738 - val_accuracy: 0.9151\n","Epoch 96/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6283 - accuracy: 0.8139 - val_loss: 1.0758 - val_accuracy: 0.9159\n","Epoch 97/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6213 - accuracy: 0.8171 - val_loss: 1.0742 - val_accuracy: 0.9148\n","Epoch 98/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6183 - accuracy: 0.8170 - val_loss: 1.0775 - val_accuracy: 0.9156\n","Epoch 99/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6161 - accuracy: 0.8171 - val_loss: 1.0796 - val_accuracy: 0.9143\n","Epoch 100/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6180 - accuracy: 0.8161 - val_loss: 1.0746 - val_accuracy: 0.9142\n","Epoch 101/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.6092 - accuracy: 0.8188 - val_loss: 1.0692 - val_accuracy: 0.9151\n","Epoch 102/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.6008 - accuracy: 0.8224 - val_loss: 1.0724 - val_accuracy: 0.9154\n","Epoch 103/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5929 - accuracy: 0.8248 - val_loss: 1.0799 - val_accuracy: 0.9135\n","Epoch 104/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5954 - accuracy: 0.8221 - val_loss: 1.0644 - val_accuracy: 0.9168\n","Epoch 105/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5861 - accuracy: 0.8268 - val_loss: 1.0662 - val_accuracy: 0.9159\n","Epoch 106/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5969 - accuracy: 0.8225 - val_loss: 1.0678 - val_accuracy: 0.9154\n","Epoch 107/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5892 - accuracy: 0.8243 - val_loss: 1.0690 - val_accuracy: 0.9147\n","Epoch 108/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5864 - accuracy: 0.8249 - val_loss: 1.0709 - val_accuracy: 0.9139\n","Epoch 109/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.5773 - accuracy: 0.8275 - val_loss: 1.0674 - val_accuracy: 0.9155\n","Epoch 110/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.5797 - accuracy: 0.8263 - val_loss: 1.0635 - val_accuracy: 0.9160\n","Epoch 111/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5774 - accuracy: 0.8278 - val_loss: 1.0678 - val_accuracy: 0.9159\n","Epoch 112/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5713 - accuracy: 0.8293 - val_loss: 1.0634 - val_accuracy: 0.9140\n","Epoch 113/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5638 - accuracy: 0.8305 - val_loss: 1.0680 - val_accuracy: 0.9148\n","Epoch 114/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.5560 - accuracy: 0.8336 - val_loss: 1.0717 - val_accuracy: 0.9134\n","Epoch 115/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.5679 - accuracy: 0.8284 - val_loss: 1.0622 - val_accuracy: 0.9151\n","Epoch 116/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.5546 - accuracy: 0.8332 - val_loss: 1.0658 - val_accuracy: 0.9155\n","Epoch 117/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5541 - accuracy: 0.8330 - val_loss: 1.0605 - val_accuracy: 0.9160\n","Epoch 118/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.5467 - accuracy: 0.8349 - val_loss: 1.0604 - val_accuracy: 0.9144\n","Epoch 119/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5487 - accuracy: 0.8342 - val_loss: 1.0662 - val_accuracy: 0.9124\n","Epoch 120/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5438 - accuracy: 0.8347 - val_loss: 1.0660 - val_accuracy: 0.9140\n","Epoch 121/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5359 - accuracy: 0.8381 - val_loss: 1.0742 - val_accuracy: 0.9114\n","Epoch 122/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5352 - accuracy: 0.8375 - val_loss: 1.0612 - val_accuracy: 0.9151\n","Epoch 123/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5308 - accuracy: 0.8380 - val_loss: 1.0609 - val_accuracy: 0.9163\n","Epoch 124/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.5329 - accuracy: 0.8376 - val_loss: 1.0577 - val_accuracy: 0.9155\n","Epoch 125/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.5256 - accuracy: 0.8397 - val_loss: 1.0624 - val_accuracy: 0.9138\n","Epoch 126/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.5177 - accuracy: 0.8434 - val_loss: 1.0605 - val_accuracy: 0.9148\n","Epoch 127/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.5202 - accuracy: 0.8405 - val_loss: 1.0576 - val_accuracy: 0.9142\n","Epoch 128/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.5225 - accuracy: 0.8404 - val_loss: 1.0575 - val_accuracy: 0.9134\n","Epoch 129/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5079 - accuracy: 0.8444 - val_loss: 1.0566 - val_accuracy: 0.9142\n","Epoch 130/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.5115 - accuracy: 0.8432 - val_loss: 1.0596 - val_accuracy: 0.9138\n","Epoch 131/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.5005 - accuracy: 0.8471 - val_loss: 1.0614 - val_accuracy: 0.9148\n","Epoch 132/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.5108 - accuracy: 0.8429 - val_loss: 1.0569 - val_accuracy: 0.9143\n","Epoch 133/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.5003 - accuracy: 0.8456 - val_loss: 1.0627 - val_accuracy: 0.9127\n","Epoch 134/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.4933 - accuracy: 0.8488 - val_loss: 1.0540 - val_accuracy: 0.9145\n","Epoch 135/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4936 - accuracy: 0.8477 - val_loss: 1.0510 - val_accuracy: 0.9139\n","Epoch 136/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.4827 - accuracy: 0.8528 - val_loss: 1.0574 - val_accuracy: 0.9149\n","Epoch 137/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.4840 - accuracy: 0.8514 - val_loss: 1.0540 - val_accuracy: 0.9153\n","Epoch 138/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.4770 - accuracy: 0.8536 - val_loss: 1.0558 - val_accuracy: 0.9158\n","Epoch 139/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.4776 - accuracy: 0.8537 - val_loss: 1.0590 - val_accuracy: 0.9139\n","Epoch 140/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.4724 - accuracy: 0.8549 - val_loss: 1.0640 - val_accuracy: 0.9131\n","Epoch 141/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4675 - accuracy: 0.8563 - val_loss: 1.0657 - val_accuracy: 0.9131\n","Epoch 142/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4657 - accuracy: 0.8562 - val_loss: 1.0508 - val_accuracy: 0.9138\n","Epoch 143/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4626 - accuracy: 0.8562 - val_loss: 1.0657 - val_accuracy: 0.9129\n","Epoch 144/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4605 - accuracy: 0.8579 - val_loss: 1.0530 - val_accuracy: 0.9147\n","Epoch 145/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4569 - accuracy: 0.8580 - val_loss: 1.0544 - val_accuracy: 0.9124\n","Epoch 146/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4548 - accuracy: 0.8578 - val_loss: 1.0505 - val_accuracy: 0.9135\n","Epoch 147/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.4505 - accuracy: 0.8590 - val_loss: 1.0630 - val_accuracy: 0.9138\n","Epoch 148/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.4454 - accuracy: 0.8618 - val_loss: 1.0557 - val_accuracy: 0.9146\n","Epoch 149/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.4409 - accuracy: 0.8630 - val_loss: 1.0546 - val_accuracy: 0.9134\n","Epoch 150/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.4405 - accuracy: 0.8625 - val_loss: 1.0490 - val_accuracy: 0.9139\n","Epoch 151/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.4395 - accuracy: 0.8630 - val_loss: 1.0502 - val_accuracy: 0.9133\n","Epoch 152/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4338 - accuracy: 0.8634 - val_loss: 1.0536 - val_accuracy: 0.9150\n","Epoch 153/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4359 - accuracy: 0.8623 - val_loss: 1.0612 - val_accuracy: 0.9122\n","Epoch 154/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.4292 - accuracy: 0.8652 - val_loss: 1.0494 - val_accuracy: 0.9146\n","Epoch 155/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4215 - accuracy: 0.8678 - val_loss: 1.0472 - val_accuracy: 0.9142\n","Epoch 156/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4187 - accuracy: 0.8678 - val_loss: 1.0662 - val_accuracy: 0.9114\n","Epoch 157/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4160 - accuracy: 0.8685 - val_loss: 1.0540 - val_accuracy: 0.9140\n","Epoch 158/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4165 - accuracy: 0.8690 - val_loss: 1.0679 - val_accuracy: 0.9103\n","Epoch 159/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4093 - accuracy: 0.8706 - val_loss: 1.0544 - val_accuracy: 0.9137\n","Epoch 160/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.4077 - accuracy: 0.8715 - val_loss: 1.0553 - val_accuracy: 0.9124\n","Epoch 161/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.4018 - accuracy: 0.8729 - val_loss: 1.0563 - val_accuracy: 0.9127\n","Epoch 162/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3942 - accuracy: 0.8745 - val_loss: 1.0524 - val_accuracy: 0.9139\n","Epoch 163/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.3873 - accuracy: 0.8763 - val_loss: 1.0461 - val_accuracy: 0.9141\n","Epoch 164/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3918 - accuracy: 0.8756 - val_loss: 1.0477 - val_accuracy: 0.9142\n","Epoch 165/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.3909 - accuracy: 0.8749 - val_loss: 1.0550 - val_accuracy: 0.9131\n","Epoch 166/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3851 - accuracy: 0.8774 - val_loss: 1.0501 - val_accuracy: 0.9130\n","Epoch 167/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3887 - accuracy: 0.8762 - val_loss: 1.0524 - val_accuracy: 0.9118\n","Epoch 168/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.3784 - accuracy: 0.8787 - val_loss: 1.0496 - val_accuracy: 0.9143\n","Epoch 169/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.3751 - accuracy: 0.8797 - val_loss: 1.0492 - val_accuracy: 0.9131\n","Epoch 170/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3810 - accuracy: 0.8780 - val_loss: 1.0516 - val_accuracy: 0.9141\n","Epoch 171/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3698 - accuracy: 0.8807 - val_loss: 1.0562 - val_accuracy: 0.9126\n","Epoch 172/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.3656 - accuracy: 0.8818 - val_loss: 1.0570 - val_accuracy: 0.9120\n","Epoch 173/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.3675 - accuracy: 0.8814 - val_loss: 1.0631 - val_accuracy: 0.9120\n","Epoch 174/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3696 - accuracy: 0.8799 - val_loss: 1.0496 - val_accuracy: 0.9136\n","Epoch 175/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3626 - accuracy: 0.8827 - val_loss: 1.0430 - val_accuracy: 0.9138\n","Epoch 176/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3565 - accuracy: 0.8851 - val_loss: 1.0581 - val_accuracy: 0.9133\n","Epoch 177/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3534 - accuracy: 0.8855 - val_loss: 1.0456 - val_accuracy: 0.9133\n","Epoch 178/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3496 - accuracy: 0.8858 - val_loss: 1.0448 - val_accuracy: 0.9136\n","Epoch 179/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3418 - accuracy: 0.8873 - val_loss: 1.0443 - val_accuracy: 0.9140\n","Epoch 180/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3350 - accuracy: 0.8900 - val_loss: 1.0475 - val_accuracy: 0.9138\n","Epoch 181/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3402 - accuracy: 0.8894 - val_loss: 1.0512 - val_accuracy: 0.9117\n","Epoch 182/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3336 - accuracy: 0.8898 - val_loss: 1.0477 - val_accuracy: 0.9123\n","Epoch 183/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3298 - accuracy: 0.8906 - val_loss: 1.0528 - val_accuracy: 0.9116\n","Epoch 184/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3307 - accuracy: 0.8911 - val_loss: 1.0418 - val_accuracy: 0.9141\n","Epoch 185/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3191 - accuracy: 0.8936 - val_loss: 1.0522 - val_accuracy: 0.9135\n","Epoch 186/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3170 - accuracy: 0.8940 - val_loss: 1.0528 - val_accuracy: 0.9121\n","Epoch 187/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.3223 - accuracy: 0.8928 - val_loss: 1.0524 - val_accuracy: 0.9135\n","Epoch 188/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3138 - accuracy: 0.8945 - val_loss: 1.0474 - val_accuracy: 0.9118\n","Epoch 189/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 1.3117 - accuracy: 0.8956 - val_loss: 1.0468 - val_accuracy: 0.9137\n","Epoch 190/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3041 - accuracy: 0.8970 - val_loss: 1.0445 - val_accuracy: 0.9125\n","Epoch 191/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3059 - accuracy: 0.8965 - val_loss: 1.0420 - val_accuracy: 0.9128\n","Epoch 192/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3029 - accuracy: 0.8977 - val_loss: 1.0407 - val_accuracy: 0.9129\n","Epoch 193/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.3077 - accuracy: 0.8964 - val_loss: 1.0414 - val_accuracy: 0.9129\n","Epoch 194/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.2970 - accuracy: 0.8999 - val_loss: 1.0465 - val_accuracy: 0.9118\n","Epoch 195/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.2924 - accuracy: 0.9006 - val_loss: 1.0438 - val_accuracy: 0.9129\n","Epoch 196/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.2948 - accuracy: 0.8996 - val_loss: 1.0440 - val_accuracy: 0.9104\n","Epoch 197/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2851 - accuracy: 0.9022 - val_loss: 1.0456 - val_accuracy: 0.9136\n","Epoch 198/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2971 - accuracy: 0.8985 - val_loss: 1.0568 - val_accuracy: 0.9114\n","Epoch 199/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2835 - accuracy: 0.9018 - val_loss: 1.0417 - val_accuracy: 0.9124\n","Epoch 200/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2850 - accuracy: 0.9026 - val_loss: 1.0562 - val_accuracy: 0.9114\n","Epoch 201/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2735 - accuracy: 0.9045 - val_loss: 1.0426 - val_accuracy: 0.9131\n","Epoch 202/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2755 - accuracy: 0.9046 - val_loss: 1.0422 - val_accuracy: 0.9147\n","Epoch 203/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2747 - accuracy: 0.9046 - val_loss: 1.0421 - val_accuracy: 0.9130\n","Epoch 204/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2704 - accuracy: 0.9053 - val_loss: 1.0504 - val_accuracy: 0.9118\n","Epoch 205/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2647 - accuracy: 0.9068 - val_loss: 1.0427 - val_accuracy: 0.9116\n","Epoch 206/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2619 - accuracy: 0.9064 - val_loss: 1.0392 - val_accuracy: 0.9141\n","Epoch 207/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2602 - accuracy: 0.9077 - val_loss: 1.0497 - val_accuracy: 0.9111\n","Epoch 208/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2582 - accuracy: 0.9078 - val_loss: 1.0431 - val_accuracy: 0.9114\n","Epoch 209/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2556 - accuracy: 0.9084 - val_loss: 1.0444 - val_accuracy: 0.9121\n","Epoch 210/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2568 - accuracy: 0.9082 - val_loss: 1.0470 - val_accuracy: 0.9117\n","Epoch 211/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2509 - accuracy: 0.9093 - val_loss: 1.0440 - val_accuracy: 0.9125\n","Epoch 212/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2477 - accuracy: 0.9096 - val_loss: 1.0422 - val_accuracy: 0.9114\n","Epoch 213/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2426 - accuracy: 0.9114 - val_loss: 1.0416 - val_accuracy: 0.9115\n","Epoch 214/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2448 - accuracy: 0.9112 - val_loss: 1.0466 - val_accuracy: 0.9108\n","Epoch 215/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2319 - accuracy: 0.9147 - val_loss: 1.0407 - val_accuracy: 0.9127\n","Epoch 216/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2368 - accuracy: 0.9124 - val_loss: 1.0437 - val_accuracy: 0.9118\n","Epoch 217/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2343 - accuracy: 0.9138 - val_loss: 1.0410 - val_accuracy: 0.9128\n","Epoch 218/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2306 - accuracy: 0.9142 - val_loss: 1.0477 - val_accuracy: 0.9114\n","Epoch 219/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2258 - accuracy: 0.9148 - val_loss: 1.0434 - val_accuracy: 0.9114\n","Epoch 220/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2239 - accuracy: 0.9156 - val_loss: 1.0475 - val_accuracy: 0.9115\n","Epoch 221/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2222 - accuracy: 0.9156 - val_loss: 1.0467 - val_accuracy: 0.9100\n","Epoch 222/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2204 - accuracy: 0.9165 - val_loss: 1.0386 - val_accuracy: 0.9114\n","Epoch 223/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2171 - accuracy: 0.9169 - val_loss: 1.0419 - val_accuracy: 0.9116\n","Epoch 224/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2144 - accuracy: 0.9177 - val_loss: 1.0391 - val_accuracy: 0.9136\n","Epoch 225/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2187 - accuracy: 0.9161 - val_loss: 1.0429 - val_accuracy: 0.9119\n","Epoch 226/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2094 - accuracy: 0.9192 - val_loss: 1.0392 - val_accuracy: 0.9118\n","Epoch 227/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2131 - accuracy: 0.9167 - val_loss: 1.0422 - val_accuracy: 0.9115\n","Epoch 228/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1983 - accuracy: 0.9207 - val_loss: 1.0411 - val_accuracy: 0.9118\n","Epoch 229/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2082 - accuracy: 0.9187 - val_loss: 1.0371 - val_accuracy: 0.9105\n","Epoch 230/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2025 - accuracy: 0.9195 - val_loss: 1.0482 - val_accuracy: 0.9116\n","Epoch 231/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2028 - accuracy: 0.9196 - val_loss: 1.0450 - val_accuracy: 0.9108\n","Epoch 232/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1964 - accuracy: 0.9208 - val_loss: 1.0476 - val_accuracy: 0.9107\n","Epoch 233/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.2002 - accuracy: 0.9200 - val_loss: 1.0419 - val_accuracy: 0.9096\n","Epoch 234/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1925 - accuracy: 0.9225 - val_loss: 1.0360 - val_accuracy: 0.9127\n","Epoch 235/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1835 - accuracy: 0.9247 - val_loss: 1.0430 - val_accuracy: 0.9101\n","Epoch 236/1000\n","656/656 [==============================] - 7s 10ms/step - loss: 1.1904 - accuracy: 0.9219 - val_loss: 1.0429 - val_accuracy: 0.9114\n","Epoch 237/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1863 - accuracy: 0.9236 - val_loss: 1.0460 - val_accuracy: 0.9100\n","Epoch 238/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1897 - accuracy: 0.9219 - val_loss: 1.0375 - val_accuracy: 0.9110\n","Epoch 239/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1814 - accuracy: 0.9239 - val_loss: 1.0523 - val_accuracy: 0.9095\n","Epoch 240/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1849 - accuracy: 0.9236 - val_loss: 1.0439 - val_accuracy: 0.9109\n","Epoch 241/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1760 - accuracy: 0.9254 - val_loss: 1.0342 - val_accuracy: 0.9104\n","Epoch 242/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1731 - accuracy: 0.9254 - val_loss: 1.0454 - val_accuracy: 0.9116\n","Epoch 243/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1732 - accuracy: 0.9254 - val_loss: 1.0431 - val_accuracy: 0.9093\n","Epoch 244/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1706 - accuracy: 0.9272 - val_loss: 1.0420 - val_accuracy: 0.9105\n","Epoch 245/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1676 - accuracy: 0.9273 - val_loss: 1.0390 - val_accuracy: 0.9091\n","Epoch 246/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1710 - accuracy: 0.9261 - val_loss: 1.0466 - val_accuracy: 0.9102\n","Epoch 247/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1673 - accuracy: 0.9271 - val_loss: 1.0477 - val_accuracy: 0.9081\n","Epoch 248/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1588 - accuracy: 0.9290 - val_loss: 1.0453 - val_accuracy: 0.9100\n","Epoch 249/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1583 - accuracy: 0.9290 - val_loss: 1.0506 - val_accuracy: 0.9098\n","Epoch 250/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1554 - accuracy: 0.9297 - val_loss: 1.0342 - val_accuracy: 0.9113\n","Epoch 251/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1611 - accuracy: 0.9272 - val_loss: 1.0439 - val_accuracy: 0.9101\n","Epoch 252/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1545 - accuracy: 0.9297 - val_loss: 1.0415 - val_accuracy: 0.9110\n","Epoch 253/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1518 - accuracy: 0.9298 - val_loss: 1.0416 - val_accuracy: 0.9105\n","Epoch 254/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1562 - accuracy: 0.9278 - val_loss: 1.0354 - val_accuracy: 0.9108\n","Epoch 255/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1505 - accuracy: 0.9302 - val_loss: 1.0381 - val_accuracy: 0.9111\n","Epoch 256/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1479 - accuracy: 0.9308 - val_loss: 1.0417 - val_accuracy: 0.9107\n","Epoch 257/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1439 - accuracy: 0.9312 - val_loss: 1.0370 - val_accuracy: 0.9100\n","Epoch 258/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1420 - accuracy: 0.9315 - val_loss: 1.0490 - val_accuracy: 0.9092\n","Epoch 259/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1363 - accuracy: 0.9326 - val_loss: 1.0392 - val_accuracy: 0.9097\n","Epoch 260/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1477 - accuracy: 0.9292 - val_loss: 1.0464 - val_accuracy: 0.9103\n","Epoch 261/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1396 - accuracy: 0.9315 - val_loss: 1.0362 - val_accuracy: 0.9106\n","Epoch 262/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1322 - accuracy: 0.9331 - val_loss: 1.0369 - val_accuracy: 0.9112\n","Epoch 263/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1342 - accuracy: 0.9330 - val_loss: 1.0488 - val_accuracy: 0.9099\n","Epoch 264/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1262 - accuracy: 0.9345 - val_loss: 1.0392 - val_accuracy: 0.9110\n","Epoch 265/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1293 - accuracy: 0.9338 - val_loss: 1.0415 - val_accuracy: 0.9088\n","Epoch 266/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1299 - accuracy: 0.9336 - val_loss: 1.0444 - val_accuracy: 0.9089\n","Epoch 267/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1231 - accuracy: 0.9350 - val_loss: 1.0436 - val_accuracy: 0.9078\n","Epoch 268/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1230 - accuracy: 0.9346 - val_loss: 1.0411 - val_accuracy: 0.9106\n","Epoch 269/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1237 - accuracy: 0.9340 - val_loss: 1.0401 - val_accuracy: 0.9091\n","Epoch 270/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1180 - accuracy: 0.9357 - val_loss: 1.0362 - val_accuracy: 0.9104\n","Epoch 271/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 1.1169 - accuracy: 0.9350 - val_loss: 1.0416 - val_accuracy: 0.9108\n","Epoch 272/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1140 - accuracy: 0.9362 - val_loss: 1.0348 - val_accuracy: 0.9101\n","Epoch 273/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1113 - accuracy: 0.9373 - val_loss: 1.0483 - val_accuracy: 0.9090\n","Epoch 274/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1125 - accuracy: 0.9363 - val_loss: 1.0491 - val_accuracy: 0.9094\n","Epoch 275/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1097 - accuracy: 0.9372 - val_loss: 1.0370 - val_accuracy: 0.9096\n","Epoch 276/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1083 - accuracy: 0.9367 - val_loss: 1.0355 - val_accuracy: 0.9105\n","Epoch 277/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1135 - accuracy: 0.9360 - val_loss: 1.0362 - val_accuracy: 0.9103\n","Epoch 278/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1051 - accuracy: 0.9375 - val_loss: 1.0355 - val_accuracy: 0.9099\n","Epoch 279/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1046 - accuracy: 0.9378 - val_loss: 1.0549 - val_accuracy: 0.9098\n","Epoch 280/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0999 - accuracy: 0.9380 - val_loss: 1.0365 - val_accuracy: 0.9102\n","Epoch 281/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1040 - accuracy: 0.9376 - val_loss: 1.0480 - val_accuracy: 0.9091\n","Epoch 282/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1004 - accuracy: 0.9383 - val_loss: 1.0375 - val_accuracy: 0.9108\n","Epoch 283/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0932 - accuracy: 0.9389 - val_loss: 1.0342 - val_accuracy: 0.9094\n","Epoch 284/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0946 - accuracy: 0.9390 - val_loss: 1.0388 - val_accuracy: 0.9101\n","Epoch 285/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0949 - accuracy: 0.9388 - val_loss: 1.0364 - val_accuracy: 0.9105\n","Epoch 286/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0949 - accuracy: 0.9382 - val_loss: 1.0381 - val_accuracy: 0.9095\n","Epoch 287/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0901 - accuracy: 0.9397 - val_loss: 1.0378 - val_accuracy: 0.9084\n","Epoch 288/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0968 - accuracy: 0.9377 - val_loss: 1.0368 - val_accuracy: 0.9093\n","Epoch 289/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0836 - accuracy: 0.9410 - val_loss: 1.0319 - val_accuracy: 0.9096\n","Epoch 290/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.1028 - accuracy: 0.9356 - val_loss: 1.0507 - val_accuracy: 0.9084\n","Epoch 291/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0865 - accuracy: 0.9398 - val_loss: 1.0445 - val_accuracy: 0.9086\n","Epoch 292/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0855 - accuracy: 0.9400 - val_loss: 1.0384 - val_accuracy: 0.9107\n","Epoch 293/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0803 - accuracy: 0.9412 - val_loss: 1.0370 - val_accuracy: 0.9087\n","Epoch 294/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0811 - accuracy: 0.9408 - val_loss: 1.0384 - val_accuracy: 0.9093\n","Epoch 295/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0837 - accuracy: 0.9398 - val_loss: 1.0366 - val_accuracy: 0.9086\n","Epoch 296/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0773 - accuracy: 0.9419 - val_loss: 1.0352 - val_accuracy: 0.9099\n","Epoch 297/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0782 - accuracy: 0.9409 - val_loss: 1.0439 - val_accuracy: 0.9078\n","Epoch 298/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 1.0777 - accuracy: 0.9411 - val_loss: 1.0370 - val_accuracy: 0.9092\n","Epoch 299/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0708 - accuracy: 0.9427 - val_loss: 1.0425 - val_accuracy: 0.9096\n","Epoch 300/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0797 - accuracy: 0.9407 - val_loss: 1.0395 - val_accuracy: 0.9094\n","Epoch 301/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0680 - accuracy: 0.9432 - val_loss: 1.0406 - val_accuracy: 0.9094\n","Epoch 302/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0721 - accuracy: 0.9426 - val_loss: 1.0379 - val_accuracy: 0.9084\n","Epoch 303/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0701 - accuracy: 0.9424 - val_loss: 1.0388 - val_accuracy: 0.9081\n","Epoch 304/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0617 - accuracy: 0.9443 - val_loss: 1.0411 - val_accuracy: 0.9070\n","Epoch 305/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0681 - accuracy: 0.9430 - val_loss: 1.0393 - val_accuracy: 0.9091\n","Epoch 306/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0591 - accuracy: 0.9442 - val_loss: 1.0386 - val_accuracy: 0.9089\n","Epoch 307/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0661 - accuracy: 0.9422 - val_loss: 1.0442 - val_accuracy: 0.9084\n","Epoch 308/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0639 - accuracy: 0.9435 - val_loss: 1.0353 - val_accuracy: 0.9091\n","Epoch 309/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0600 - accuracy: 0.9439 - val_loss: 1.0359 - val_accuracy: 0.9104\n","Epoch 310/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0592 - accuracy: 0.9449 - val_loss: 1.0440 - val_accuracy: 0.9085\n","Epoch 311/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0556 - accuracy: 0.9449 - val_loss: 1.0334 - val_accuracy: 0.9097\n","Epoch 312/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0571 - accuracy: 0.9443 - val_loss: 1.0373 - val_accuracy: 0.9095\n","Epoch 313/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0546 - accuracy: 0.9445 - val_loss: 1.0368 - val_accuracy: 0.9103\n","Epoch 314/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0454 - accuracy: 0.9464 - val_loss: 1.0410 - val_accuracy: 0.9094\n","Epoch 315/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0453 - accuracy: 0.9462 - val_loss: 1.0404 - val_accuracy: 0.9089\n","Epoch 316/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0409 - accuracy: 0.9474 - val_loss: 1.0468 - val_accuracy: 0.9088\n","Epoch 317/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0424 - accuracy: 0.9467 - val_loss: 1.0369 - val_accuracy: 0.9106\n","Epoch 318/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0413 - accuracy: 0.9474 - val_loss: 1.0373 - val_accuracy: 0.9086\n","Epoch 319/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0402 - accuracy: 0.9477 - val_loss: 1.0409 - val_accuracy: 0.9067\n","Epoch 320/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0376 - accuracy: 0.9490 - val_loss: 1.0485 - val_accuracy: 0.9074\n","Epoch 321/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0285 - accuracy: 0.9506 - val_loss: 1.0386 - val_accuracy: 0.9085\n","Epoch 322/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0325 - accuracy: 0.9496 - val_loss: 1.0466 - val_accuracy: 0.9066\n","Epoch 323/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0357 - accuracy: 0.9503 - val_loss: 1.0375 - val_accuracy: 0.9103\n","Epoch 324/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0316 - accuracy: 0.9510 - val_loss: 1.0456 - val_accuracy: 0.9075\n","Epoch 325/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0180 - accuracy: 0.9549 - val_loss: 1.0407 - val_accuracy: 0.9081\n","Epoch 326/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0194 - accuracy: 0.9546 - val_loss: 1.0398 - val_accuracy: 0.9083\n","Epoch 327/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0181 - accuracy: 0.9560 - val_loss: 1.0432 - val_accuracy: 0.9085\n","Epoch 328/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0257 - accuracy: 0.9542 - val_loss: 1.0419 - val_accuracy: 0.9073\n","Epoch 329/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0081 - accuracy: 0.9574 - val_loss: 1.0391 - val_accuracy: 0.9101\n","Epoch 330/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0236 - accuracy: 0.9535 - val_loss: 1.0408 - val_accuracy: 0.9091\n","Epoch 331/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0094 - accuracy: 0.9574 - val_loss: 1.0685 - val_accuracy: 0.9056\n","Epoch 332/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0117 - accuracy: 0.9575 - val_loss: 1.0470 - val_accuracy: 0.9082\n","Epoch 333/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0068 - accuracy: 0.9587 - val_loss: 1.0442 - val_accuracy: 0.9091\n","Epoch 334/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0068 - accuracy: 0.9578 - val_loss: 1.0363 - val_accuracy: 0.9090\n","Epoch 335/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0059 - accuracy: 0.9584 - val_loss: 1.0416 - val_accuracy: 0.9082\n","Epoch 336/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0002 - accuracy: 0.9597 - val_loss: 1.0382 - val_accuracy: 0.9081\n","Epoch 337/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0075 - accuracy: 0.9575 - val_loss: 1.0414 - val_accuracy: 0.9091\n","Epoch 338/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0059 - accuracy: 0.9585 - val_loss: 1.0609 - val_accuracy: 0.9065\n","Epoch 339/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9963 - accuracy: 0.9609 - val_loss: 1.0447 - val_accuracy: 0.9076\n","Epoch 340/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0008 - accuracy: 0.9594 - val_loss: 1.0365 - val_accuracy: 0.9088\n","Epoch 341/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9968 - accuracy: 0.9598 - val_loss: 1.0370 - val_accuracy: 0.9086\n","Epoch 342/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9883 - accuracy: 0.9616 - val_loss: 1.0354 - val_accuracy: 0.9085\n","Epoch 343/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9963 - accuracy: 0.9600 - val_loss: 1.0385 - val_accuracy: 0.9082\n","Epoch 344/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.9937 - accuracy: 0.9604 - val_loss: 1.0400 - val_accuracy: 0.9079\n","Epoch 345/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9952 - accuracy: 0.9603 - val_loss: 1.0420 - val_accuracy: 0.9088\n","Epoch 346/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9940 - accuracy: 0.9605 - val_loss: 1.0463 - val_accuracy: 0.9074\n","Epoch 347/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9908 - accuracy: 0.9604 - val_loss: 1.0334 - val_accuracy: 0.9093\n","Epoch 348/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9882 - accuracy: 0.9617 - val_loss: 1.0385 - val_accuracy: 0.9093\n","Epoch 349/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9820 - accuracy: 0.9625 - val_loss: 1.0451 - val_accuracy: 0.9079\n","Epoch 350/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9936 - accuracy: 0.9582 - val_loss: 1.0409 - val_accuracy: 0.9088\n","Epoch 351/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9797 - accuracy: 0.9630 - val_loss: 1.0328 - val_accuracy: 0.9094\n","Epoch 352/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9799 - accuracy: 0.9634 - val_loss: 1.0394 - val_accuracy: 0.9095\n","Epoch 353/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9821 - accuracy: 0.9621 - val_loss: 1.0473 - val_accuracy: 0.9073\n","Epoch 354/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9808 - accuracy: 0.9619 - val_loss: 1.0580 - val_accuracy: 0.9030\n","Epoch 355/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.9900 - accuracy: 0.9601 - val_loss: 1.0370 - val_accuracy: 0.9092\n","Epoch 356/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9819 - accuracy: 0.9623 - val_loss: 1.0479 - val_accuracy: 0.9069\n","Epoch 357/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9712 - accuracy: 0.9644 - val_loss: 1.0412 - val_accuracy: 0.9074\n","Epoch 358/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9706 - accuracy: 0.9648 - val_loss: 1.0364 - val_accuracy: 0.9081\n","Epoch 359/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9682 - accuracy: 0.9649 - val_loss: 1.0387 - val_accuracy: 0.9089\n","Epoch 360/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9702 - accuracy: 0.9645 - val_loss: 1.0365 - val_accuracy: 0.9088\n","Epoch 361/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9682 - accuracy: 0.9643 - val_loss: 1.0401 - val_accuracy: 0.9078\n","Epoch 362/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9713 - accuracy: 0.9636 - val_loss: 1.0421 - val_accuracy: 0.9074\n","Epoch 363/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9610 - accuracy: 0.9655 - val_loss: 1.0447 - val_accuracy: 0.9079\n","Epoch 364/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9598 - accuracy: 0.9660 - val_loss: 1.0350 - val_accuracy: 0.9081\n","Epoch 365/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9647 - accuracy: 0.9651 - val_loss: 1.0397 - val_accuracy: 0.9073\n","Epoch 366/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9646 - accuracy: 0.9645 - val_loss: 1.0370 - val_accuracy: 0.9080\n","Epoch 367/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9592 - accuracy: 0.9661 - val_loss: 1.0357 - val_accuracy: 0.9088\n","Epoch 368/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9652 - accuracy: 0.9649 - val_loss: 1.0389 - val_accuracy: 0.9078\n","Epoch 369/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9622 - accuracy: 0.9645 - val_loss: 1.0371 - val_accuracy: 0.9081\n","Epoch 370/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9562 - accuracy: 0.9663 - val_loss: 1.0443 - val_accuracy: 0.9053\n","Epoch 371/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9559 - accuracy: 0.9658 - val_loss: 1.0351 - val_accuracy: 0.9071\n","Epoch 372/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9542 - accuracy: 0.9663 - val_loss: 1.0416 - val_accuracy: 0.9070\n","Epoch 373/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9958 - accuracy: 0.9543 - val_loss: 1.0529 - val_accuracy: 0.9073\n","Epoch 374/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9478 - accuracy: 0.9674 - val_loss: 1.0358 - val_accuracy: 0.9076\n","Epoch 375/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9494 - accuracy: 0.9668 - val_loss: 1.0367 - val_accuracy: 0.9066\n","Epoch 376/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9515 - accuracy: 0.9663 - val_loss: 1.0441 - val_accuracy: 0.9049\n","Epoch 377/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9568 - accuracy: 0.9647 - val_loss: 1.0417 - val_accuracy: 0.9079\n","Epoch 378/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9670 - accuracy: 0.9623 - val_loss: 1.0445 - val_accuracy: 0.9056\n","Epoch 379/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9480 - accuracy: 0.9670 - val_loss: 1.0384 - val_accuracy: 0.9086\n","Epoch 380/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9493 - accuracy: 0.9663 - val_loss: 1.0353 - val_accuracy: 0.9084\n","Epoch 381/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9441 - accuracy: 0.9678 - val_loss: 1.0373 - val_accuracy: 0.9081\n","Epoch 382/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9439 - accuracy: 0.9677 - val_loss: 1.0352 - val_accuracy: 0.9093\n","Epoch 383/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9352 - accuracy: 0.9689 - val_loss: 1.0370 - val_accuracy: 0.9075\n","Epoch 384/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9416 - accuracy: 0.9688 - val_loss: 1.0375 - val_accuracy: 0.9064\n","Epoch 385/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9397 - accuracy: 0.9680 - val_loss: 1.0361 - val_accuracy: 0.9063\n","Epoch 386/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9393 - accuracy: 0.9680 - val_loss: 1.0320 - val_accuracy: 0.9072\n","Epoch 387/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9377 - accuracy: 0.9685 - val_loss: 1.0349 - val_accuracy: 0.9073\n","Epoch 388/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9411 - accuracy: 0.9675 - val_loss: 1.0448 - val_accuracy: 0.9048\n","Epoch 389/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.9319 - accuracy: 0.9693 - val_loss: 1.0419 - val_accuracy: 0.9079\n","Epoch 390/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9354 - accuracy: 0.9685 - val_loss: 1.0331 - val_accuracy: 0.9086\n","Epoch 391/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9325 - accuracy: 0.9689 - val_loss: 1.0388 - val_accuracy: 0.9076\n","Epoch 392/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9399 - accuracy: 0.9671 - val_loss: 1.0326 - val_accuracy: 0.9079\n","Epoch 393/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9462 - accuracy: 0.9647 - val_loss: 1.0401 - val_accuracy: 0.9066\n","Epoch 394/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9431 - accuracy: 0.9656 - val_loss: 1.0327 - val_accuracy: 0.9073\n","Epoch 395/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9312 - accuracy: 0.9692 - val_loss: 1.0359 - val_accuracy: 0.9076\n","Epoch 396/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9306 - accuracy: 0.9688 - val_loss: 1.0371 - val_accuracy: 0.9078\n","Epoch 397/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9405 - accuracy: 0.9654 - val_loss: 1.0434 - val_accuracy: 0.9066\n","Epoch 398/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9262 - accuracy: 0.9699 - val_loss: 1.0389 - val_accuracy: 0.9065\n","Epoch 399/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9316 - accuracy: 0.9684 - val_loss: 1.0406 - val_accuracy: 0.9072\n","Epoch 400/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9328 - accuracy: 0.9676 - val_loss: 1.0379 - val_accuracy: 0.9071\n","Epoch 401/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9262 - accuracy: 0.9696 - val_loss: 1.0357 - val_accuracy: 0.9073\n","Epoch 402/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9328 - accuracy: 0.9671 - val_loss: 1.0372 - val_accuracy: 0.9076\n","Epoch 403/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9227 - accuracy: 0.9698 - val_loss: 1.0454 - val_accuracy: 0.9055\n","Epoch 404/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9270 - accuracy: 0.9692 - val_loss: 1.0372 - val_accuracy: 0.9075\n","Epoch 405/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9163 - accuracy: 0.9712 - val_loss: 1.0444 - val_accuracy: 0.9066\n","Epoch 406/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9192 - accuracy: 0.9709 - val_loss: 1.0482 - val_accuracy: 0.9062\n","Epoch 407/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.9162 - accuracy: 0.9713 - val_loss: 1.0359 - val_accuracy: 0.9065\n","Epoch 408/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9233 - accuracy: 0.9697 - val_loss: 1.0440 - val_accuracy: 0.9065\n","Epoch 409/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9212 - accuracy: 0.9695 - val_loss: 1.0394 - val_accuracy: 0.9058\n","Epoch 410/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9137 - accuracy: 0.9715 - val_loss: 1.0316 - val_accuracy: 0.9083\n","Epoch 411/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9161 - accuracy: 0.9703 - val_loss: 1.0415 - val_accuracy: 0.9074\n","Epoch 412/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9120 - accuracy: 0.9715 - val_loss: 1.0448 - val_accuracy: 0.9052\n","Epoch 413/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9157 - accuracy: 0.9706 - val_loss: 1.0480 - val_accuracy: 0.9052\n","Epoch 414/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9212 - accuracy: 0.9693 - val_loss: 1.0349 - val_accuracy: 0.9072\n","Epoch 415/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9155 - accuracy: 0.9707 - val_loss: 1.0401 - val_accuracy: 0.9062\n","Epoch 416/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9459 - accuracy: 0.9631 - val_loss: 1.0370 - val_accuracy: 0.9067\n","Epoch 417/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9733 - accuracy: 0.9559 - val_loss: 1.0367 - val_accuracy: 0.9062\n","Epoch 418/1000\n","656/656 [==============================] - 7s 10ms/step - loss: 0.9169 - accuracy: 0.9700 - val_loss: 1.0325 - val_accuracy: 0.9089\n","Epoch 419/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9106 - accuracy: 0.9714 - val_loss: 1.0404 - val_accuracy: 0.9067\n","Epoch 420/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9110 - accuracy: 0.9707 - val_loss: 1.0311 - val_accuracy: 0.9078\n","Epoch 421/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9097 - accuracy: 0.9711 - val_loss: 1.0419 - val_accuracy: 0.9074\n","Epoch 422/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9016 - accuracy: 0.9730 - val_loss: 1.0407 - val_accuracy: 0.9068\n","Epoch 423/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9074 - accuracy: 0.9718 - val_loss: 1.0390 - val_accuracy: 0.9066\n","Epoch 424/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9039 - accuracy: 0.9724 - val_loss: 1.0432 - val_accuracy: 0.9061\n","Epoch 425/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.9071 - accuracy: 0.9718 - val_loss: 1.0403 - val_accuracy: 0.9059\n","Epoch 426/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9062 - accuracy: 0.9708 - val_loss: 1.0320 - val_accuracy: 0.9061\n","Epoch 427/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8976 - accuracy: 0.9736 - val_loss: 1.0362 - val_accuracy: 0.9056\n","Epoch 428/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8993 - accuracy: 0.9734 - val_loss: 1.0319 - val_accuracy: 0.9085\n","Epoch 429/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8950 - accuracy: 0.9737 - val_loss: 1.0345 - val_accuracy: 0.9071\n","Epoch 430/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9015 - accuracy: 0.9723 - val_loss: 1.0403 - val_accuracy: 0.9058\n","Epoch 431/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8957 - accuracy: 0.9736 - val_loss: 1.0375 - val_accuracy: 0.9066\n","Epoch 432/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8950 - accuracy: 0.9731 - val_loss: 1.0339 - val_accuracy: 0.9064\n","Epoch 433/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8984 - accuracy: 0.9723 - val_loss: 1.0478 - val_accuracy: 0.9046\n","Epoch 434/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8979 - accuracy: 0.9722 - val_loss: 1.0306 - val_accuracy: 0.9079\n","Epoch 435/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8940 - accuracy: 0.9734 - val_loss: 1.0382 - val_accuracy: 0.9058\n","Epoch 436/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8989 - accuracy: 0.9724 - val_loss: 1.0376 - val_accuracy: 0.9062\n","Epoch 437/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8966 - accuracy: 0.9726 - val_loss: 1.0348 - val_accuracy: 0.9065\n","Epoch 438/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8970 - accuracy: 0.9725 - val_loss: 1.0339 - val_accuracy: 0.9068\n","Epoch 439/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8909 - accuracy: 0.9734 - val_loss: 1.0399 - val_accuracy: 0.9080\n","Epoch 440/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8927 - accuracy: 0.9731 - val_loss: 1.0356 - val_accuracy: 0.9071\n","Epoch 441/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8885 - accuracy: 0.9740 - val_loss: 1.0321 - val_accuracy: 0.9071\n","Epoch 442/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8931 - accuracy: 0.9733 - val_loss: 1.0479 - val_accuracy: 0.9045\n","Epoch 443/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9177 - accuracy: 0.9671 - val_loss: 1.0424 - val_accuracy: 0.9061\n","Epoch 444/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9011 - accuracy: 0.9711 - val_loss: 1.0386 - val_accuracy: 0.9070\n","Epoch 445/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8836 - accuracy: 0.9748 - val_loss: 1.0301 - val_accuracy: 0.9083\n","Epoch 446/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8876 - accuracy: 0.9741 - val_loss: 1.0409 - val_accuracy: 0.9050\n","Epoch 447/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9844 - accuracy: 0.9511 - val_loss: 1.0464 - val_accuracy: 0.9068\n","Epoch 448/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8858 - accuracy: 0.9748 - val_loss: 1.0301 - val_accuracy: 0.9069\n","Epoch 449/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8851 - accuracy: 0.9744 - val_loss: 1.0353 - val_accuracy: 0.9080\n","Epoch 450/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8889 - accuracy: 0.9735 - val_loss: 1.0410 - val_accuracy: 0.9069\n","Epoch 451/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8854 - accuracy: 0.9742 - val_loss: 1.0363 - val_accuracy: 0.9062\n","Epoch 452/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8858 - accuracy: 0.9738 - val_loss: 1.0371 - val_accuracy: 0.9068\n","Epoch 453/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8928 - accuracy: 0.9713 - val_loss: 1.0548 - val_accuracy: 0.9032\n","Epoch 454/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8802 - accuracy: 0.9747 - val_loss: 1.0372 - val_accuracy: 0.9048\n","Epoch 455/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9517 - accuracy: 0.9579 - val_loss: 1.0411 - val_accuracy: 0.9064\n","Epoch 456/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8807 - accuracy: 0.9745 - val_loss: 1.0325 - val_accuracy: 0.9070\n","Epoch 457/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8772 - accuracy: 0.9750 - val_loss: 1.0449 - val_accuracy: 0.9055\n","Epoch 458/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8873 - accuracy: 0.9725 - val_loss: 1.0346 - val_accuracy: 0.9055\n","Epoch 459/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8755 - accuracy: 0.9755 - val_loss: 1.0345 - val_accuracy: 0.9059\n","Epoch 460/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8743 - accuracy: 0.9752 - val_loss: 1.0359 - val_accuracy: 0.9055\n","Epoch 461/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9205 - accuracy: 0.9650 - val_loss: 1.0396 - val_accuracy: 0.9049\n","Epoch 462/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8704 - accuracy: 0.9762 - val_loss: 1.0331 - val_accuracy: 0.9063\n","Epoch 463/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8799 - accuracy: 0.9739 - val_loss: 1.0340 - val_accuracy: 0.9063\n","Epoch 464/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8780 - accuracy: 0.9742 - val_loss: 1.0315 - val_accuracy: 0.9063\n","Epoch 465/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8736 - accuracy: 0.9751 - val_loss: 1.0331 - val_accuracy: 0.9068\n","Epoch 466/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8773 - accuracy: 0.9738 - val_loss: 1.0333 - val_accuracy: 0.9047\n","Epoch 467/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8708 - accuracy: 0.9755 - val_loss: 1.0315 - val_accuracy: 0.9059\n","Epoch 468/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8729 - accuracy: 0.9755 - val_loss: 1.0402 - val_accuracy: 0.9056\n","Epoch 469/1000\n","656/656 [==============================] - 7s 10ms/step - loss: 0.8706 - accuracy: 0.9750 - val_loss: 1.0359 - val_accuracy: 0.9065\n","Epoch 470/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8719 - accuracy: 0.9747 - val_loss: 1.0396 - val_accuracy: 0.9069\n","Epoch 471/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8729 - accuracy: 0.9751 - val_loss: 1.0387 - val_accuracy: 0.9063\n","Epoch 472/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8676 - accuracy: 0.9762 - val_loss: 1.0400 - val_accuracy: 0.9056\n","Epoch 473/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8706 - accuracy: 0.9752 - val_loss: 1.0319 - val_accuracy: 0.9065\n","Epoch 474/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8628 - accuracy: 0.9769 - val_loss: 1.0411 - val_accuracy: 0.9063\n","Epoch 475/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8746 - accuracy: 0.9737 - val_loss: 1.0347 - val_accuracy: 0.9052\n","Epoch 476/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8660 - accuracy: 0.9757 - val_loss: 1.0323 - val_accuracy: 0.9057\n","Epoch 477/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8596 - accuracy: 0.9769 - val_loss: 1.0301 - val_accuracy: 0.9075\n","Epoch 478/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8710 - accuracy: 0.9749 - val_loss: 1.0445 - val_accuracy: 0.9027\n","Epoch 479/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8775 - accuracy: 0.9732 - val_loss: 1.0362 - val_accuracy: 0.9059\n","Epoch 480/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8652 - accuracy: 0.9760 - val_loss: 1.0366 - val_accuracy: 0.9078\n","Epoch 481/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.9879 - accuracy: 0.9438 - val_loss: 1.0341 - val_accuracy: 0.9061\n","Epoch 482/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8769 - accuracy: 0.9726 - val_loss: 1.0356 - val_accuracy: 0.9060\n","Epoch 483/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8600 - accuracy: 0.9762 - val_loss: 1.0391 - val_accuracy: 0.9060\n","Epoch 484/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8619 - accuracy: 0.9763 - val_loss: 1.0612 - val_accuracy: 0.9006\n","Epoch 485/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9324 - accuracy: 0.9612 - val_loss: 1.0520 - val_accuracy: 0.9029\n","Epoch 486/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9160 - accuracy: 0.9655 - val_loss: 1.0489 - val_accuracy: 0.9054\n","Epoch 487/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9099 - accuracy: 0.9672 - val_loss: 1.0423 - val_accuracy: 0.9059\n","Epoch 488/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8835 - accuracy: 0.9720 - val_loss: 1.0347 - val_accuracy: 0.9052\n","Epoch 489/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8635 - accuracy: 0.9757 - val_loss: 1.0408 - val_accuracy: 0.9056\n","Epoch 490/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8511 - accuracy: 0.9776 - val_loss: 1.0414 - val_accuracy: 0.9058\n","Epoch 491/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8570 - accuracy: 0.9765 - val_loss: 1.0334 - val_accuracy: 0.9068\n","Epoch 492/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8553 - accuracy: 0.9769 - val_loss: 1.0330 - val_accuracy: 0.9057\n","Epoch 493/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8542 - accuracy: 0.9768 - val_loss: 1.0354 - val_accuracy: 0.9055\n","Epoch 494/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8524 - accuracy: 0.9772 - val_loss: 1.0393 - val_accuracy: 0.9052\n","Epoch 495/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8543 - accuracy: 0.9773 - val_loss: 1.0318 - val_accuracy: 0.9082\n","Epoch 496/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8514 - accuracy: 0.9774 - val_loss: 1.0343 - val_accuracy: 0.9057\n","Epoch 497/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.9095 - accuracy: 0.9648 - val_loss: 1.0379 - val_accuracy: 0.9056\n","Epoch 498/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8528 - accuracy: 0.9766 - val_loss: 1.0329 - val_accuracy: 0.9054\n","Epoch 499/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8500 - accuracy: 0.9777 - val_loss: 1.0414 - val_accuracy: 0.9040\n","Epoch 500/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0881 - accuracy: 0.9211 - val_loss: 1.0616 - val_accuracy: 0.9031\n","Epoch 501/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9995 - accuracy: 0.9465 - val_loss: 1.0459 - val_accuracy: 0.9050\n","Epoch 502/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 1.0217 - accuracy: 0.9417 - val_loss: 1.0527 - val_accuracy: 0.9036\n","Epoch 503/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9529 - accuracy: 0.9598 - val_loss: 1.0482 - val_accuracy: 0.9025\n","Epoch 504/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9429 - accuracy: 0.9617 - val_loss: 1.0562 - val_accuracy: 0.9032\n","Epoch 505/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9535 - accuracy: 0.9593 - val_loss: 1.0471 - val_accuracy: 0.9033\n","Epoch 506/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9221 - accuracy: 0.9662 - val_loss: 1.0546 - val_accuracy: 0.9026\n","Epoch 507/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9209 - accuracy: 0.9669 - val_loss: 1.0521 - val_accuracy: 0.9037\n","Epoch 508/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.9192 - accuracy: 0.9672 - val_loss: 1.0471 - val_accuracy: 0.9051\n","Epoch 509/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9080 - accuracy: 0.9693 - val_loss: 1.0443 - val_accuracy: 0.9054\n","Epoch 510/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9035 - accuracy: 0.9701 - val_loss: 1.0564 - val_accuracy: 0.9011\n","Epoch 511/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.9098 - accuracy: 0.9686 - val_loss: 1.0455 - val_accuracy: 0.9045\n","Epoch 512/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9013 - accuracy: 0.9702 - val_loss: 1.0491 - val_accuracy: 0.9050\n","Epoch 513/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8987 - accuracy: 0.9705 - val_loss: 1.0560 - val_accuracy: 0.9026\n","Epoch 514/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8889 - accuracy: 0.9731 - val_loss: 1.0451 - val_accuracy: 0.9041\n","Epoch 515/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8912 - accuracy: 0.9720 - val_loss: 1.0438 - val_accuracy: 0.9050\n","Epoch 516/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9567 - accuracy: 0.9569 - val_loss: 1.0577 - val_accuracy: 0.9042\n","Epoch 517/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9614 - accuracy: 0.9586 - val_loss: 1.0556 - val_accuracy: 0.9044\n","Epoch 518/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9531 - accuracy: 0.9614 - val_loss: 1.0512 - val_accuracy: 0.9038\n","Epoch 519/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9346 - accuracy: 0.9651 - val_loss: 1.0516 - val_accuracy: 0.9046\n","Epoch 520/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9222 - accuracy: 0.9679 - val_loss: 1.0580 - val_accuracy: 0.9029\n","Epoch 521/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9170 - accuracy: 0.9693 - val_loss: 1.0613 - val_accuracy: 0.9020\n","Epoch 522/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9131 - accuracy: 0.9699 - val_loss: 1.0469 - val_accuracy: 0.9041\n","Epoch 523/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9107 - accuracy: 0.9705 - val_loss: 1.0457 - val_accuracy: 0.9035\n","Epoch 524/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.9029 - accuracy: 0.9715 - val_loss: 1.0484 - val_accuracy: 0.9036\n","Epoch 525/1000\n","656/656 [==============================] - 7s 10ms/step - loss: 0.8997 - accuracy: 0.9717 - val_loss: 1.0440 - val_accuracy: 0.9048\n","Epoch 526/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8982 - accuracy: 0.9721 - val_loss: 1.0544 - val_accuracy: 0.9046\n","Epoch 527/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8916 - accuracy: 0.9727 - val_loss: 1.0544 - val_accuracy: 0.9041\n","Epoch 528/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8977 - accuracy: 0.9714 - val_loss: 1.0396 - val_accuracy: 0.9053\n","Epoch 529/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8842 - accuracy: 0.9739 - val_loss: 1.0525 - val_accuracy: 0.9039\n","Epoch 530/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8859 - accuracy: 0.9735 - val_loss: 1.0433 - val_accuracy: 0.9046\n","Epoch 531/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8854 - accuracy: 0.9736 - val_loss: 1.0461 - val_accuracy: 0.9041\n","Epoch 532/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8826 - accuracy: 0.9736 - val_loss: 1.0581 - val_accuracy: 0.9029\n","Epoch 533/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8792 - accuracy: 0.9740 - val_loss: 1.0505 - val_accuracy: 0.9036\n","Epoch 534/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8794 - accuracy: 0.9740 - val_loss: 1.0463 - val_accuracy: 0.9031\n","Epoch 535/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8788 - accuracy: 0.9734 - val_loss: 1.0428 - val_accuracy: 0.9050\n","Epoch 536/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8764 - accuracy: 0.9744 - val_loss: 1.0451 - val_accuracy: 0.9052\n","Epoch 537/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8738 - accuracy: 0.9745 - val_loss: 1.0476 - val_accuracy: 0.9038\n","Epoch 538/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8650 - accuracy: 0.9755 - val_loss: 1.0441 - val_accuracy: 0.9040\n","Epoch 539/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8673 - accuracy: 0.9755 - val_loss: 1.0491 - val_accuracy: 0.9034\n","Epoch 540/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8629 - accuracy: 0.9760 - val_loss: 1.0515 - val_accuracy: 0.9032\n","Epoch 541/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8706 - accuracy: 0.9747 - val_loss: 1.0496 - val_accuracy: 0.9044\n","Epoch 542/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8616 - accuracy: 0.9764 - val_loss: 1.0449 - val_accuracy: 0.9046\n","Epoch 543/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8567 - accuracy: 0.9768 - val_loss: 1.0409 - val_accuracy: 0.9043\n","Epoch 544/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8619 - accuracy: 0.9760 - val_loss: 1.0442 - val_accuracy: 0.9040\n","Epoch 545/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8622 - accuracy: 0.9760 - val_loss: 1.0517 - val_accuracy: 0.9042\n","Epoch 546/1000\n","656/656 [==============================] - 5s 8ms/step - loss: 0.8582 - accuracy: 0.9759 - val_loss: 1.0398 - val_accuracy: 0.9037\n","Epoch 547/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8562 - accuracy: 0.9763 - val_loss: 1.0412 - val_accuracy: 0.9049\n","Epoch 548/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8565 - accuracy: 0.9768 - val_loss: 1.0440 - val_accuracy: 0.9040\n","Epoch 549/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8554 - accuracy: 0.9762 - val_loss: 1.0488 - val_accuracy: 0.9022\n","Epoch 550/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8578 - accuracy: 0.9761 - val_loss: 1.0621 - val_accuracy: 0.9033\n","Epoch 551/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8580 - accuracy: 0.9756 - val_loss: 1.0459 - val_accuracy: 0.9046\n","Epoch 552/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8548 - accuracy: 0.9761 - val_loss: 1.0396 - val_accuracy: 0.9037\n","Epoch 553/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8493 - accuracy: 0.9772 - val_loss: 1.0518 - val_accuracy: 0.9034\n","Epoch 554/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8531 - accuracy: 0.9767 - val_loss: 1.0369 - val_accuracy: 0.9051\n","Epoch 555/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8475 - accuracy: 0.9772 - val_loss: 1.0370 - val_accuracy: 0.9054\n","Epoch 556/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8534 - accuracy: 0.9759 - val_loss: 1.0389 - val_accuracy: 0.9047\n","Epoch 557/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8440 - accuracy: 0.9778 - val_loss: 1.0463 - val_accuracy: 0.9030\n","Epoch 558/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8447 - accuracy: 0.9774 - val_loss: 1.0487 - val_accuracy: 0.9012\n","Epoch 559/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8403 - accuracy: 0.9782 - val_loss: 1.0443 - val_accuracy: 0.9049\n","Epoch 560/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8456 - accuracy: 0.9770 - val_loss: 1.0388 - val_accuracy: 0.9053\n","Epoch 561/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8471 - accuracy: 0.9766 - val_loss: 1.0398 - val_accuracy: 0.9042\n","Epoch 562/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8409 - accuracy: 0.9777 - val_loss: 1.0424 - val_accuracy: 0.9046\n","Epoch 563/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8389 - accuracy: 0.9776 - val_loss: 1.0473 - val_accuracy: 0.9037\n","Epoch 564/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8412 - accuracy: 0.9778 - val_loss: 1.0492 - val_accuracy: 0.9058\n","Epoch 565/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8398 - accuracy: 0.9781 - val_loss: 1.0498 - val_accuracy: 0.9036\n","Epoch 566/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8390 - accuracy: 0.9777 - val_loss: 1.0501 - val_accuracy: 0.9032\n","Epoch 567/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8380 - accuracy: 0.9774 - val_loss: 1.0399 - val_accuracy: 0.9037\n","Epoch 568/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8359 - accuracy: 0.9780 - val_loss: 1.0514 - val_accuracy: 0.9031\n","Epoch 569/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8358 - accuracy: 0.9781 - val_loss: 1.0355 - val_accuracy: 0.9040\n","Epoch 570/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8296 - accuracy: 0.9792 - val_loss: 1.0351 - val_accuracy: 0.9041\n","Epoch 571/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8323 - accuracy: 0.9791 - val_loss: 1.0458 - val_accuracy: 0.9044\n","Epoch 572/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8281 - accuracy: 0.9790 - val_loss: 1.0381 - val_accuracy: 0.9047\n","Epoch 573/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8311 - accuracy: 0.9788 - val_loss: 1.0370 - val_accuracy: 0.9042\n","Epoch 574/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8305 - accuracy: 0.9782 - val_loss: 1.0396 - val_accuracy: 0.9045\n","Epoch 575/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8331 - accuracy: 0.9778 - val_loss: 1.0390 - val_accuracy: 0.9052\n","Epoch 576/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8298 - accuracy: 0.9790 - val_loss: 1.0448 - val_accuracy: 0.9040\n","Epoch 577/1000\n","656/656 [==============================] - 7s 10ms/step - loss: 0.8245 - accuracy: 0.9796 - val_loss: 1.0439 - val_accuracy: 0.9034\n","Epoch 578/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8264 - accuracy: 0.9793 - val_loss: 1.0443 - val_accuracy: 0.9045\n","Epoch 579/1000\n","656/656 [==============================] - 7s 11ms/step - loss: 0.8270 - accuracy: 0.9786 - val_loss: 1.0466 - val_accuracy: 0.9037\n","Epoch 580/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8248 - accuracy: 0.9792 - val_loss: 1.0400 - val_accuracy: 0.9047\n","Epoch 581/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8259 - accuracy: 0.9790 - val_loss: 1.0388 - val_accuracy: 0.9043\n","Epoch 582/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8239 - accuracy: 0.9792 - val_loss: 1.0502 - val_accuracy: 0.9034\n","Epoch 583/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8270 - accuracy: 0.9786 - val_loss: 1.0494 - val_accuracy: 0.9029\n","Epoch 584/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8243 - accuracy: 0.9791 - val_loss: 1.0717 - val_accuracy: 0.8988\n","Epoch 585/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8344 - accuracy: 0.9761 - val_loss: 1.0352 - val_accuracy: 0.9045\n","Epoch 586/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8241 - accuracy: 0.9791 - val_loss: 1.0416 - val_accuracy: 0.9015\n","Epoch 587/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8239 - accuracy: 0.9787 - val_loss: 1.0360 - val_accuracy: 0.9044\n","Epoch 588/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8212 - accuracy: 0.9792 - val_loss: 1.0451 - val_accuracy: 0.9030\n","Epoch 589/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8176 - accuracy: 0.9799 - val_loss: 1.0391 - val_accuracy: 0.9054\n","Epoch 590/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8192 - accuracy: 0.9791 - val_loss: 1.0425 - val_accuracy: 0.9031\n","Epoch 591/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8195 - accuracy: 0.9795 - val_loss: 1.0394 - val_accuracy: 0.9034\n","Epoch 592/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8231 - accuracy: 0.9786 - val_loss: 1.0486 - val_accuracy: 0.9032\n","Epoch 593/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8161 - accuracy: 0.9795 - val_loss: 1.0444 - val_accuracy: 0.9028\n","Epoch 594/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8170 - accuracy: 0.9795 - val_loss: 1.0380 - val_accuracy: 0.9037\n","Epoch 595/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8155 - accuracy: 0.9796 - val_loss: 1.0364 - val_accuracy: 0.9045\n","Epoch 596/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8143 - accuracy: 0.9797 - val_loss: 1.0471 - val_accuracy: 0.9012\n","Epoch 597/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8129 - accuracy: 0.9802 - val_loss: 1.0520 - val_accuracy: 0.9017\n","Epoch 598/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8526 - accuracy: 0.9705 - val_loss: 1.0392 - val_accuracy: 0.9039\n","Epoch 599/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8108 - accuracy: 0.9799 - val_loss: 1.0433 - val_accuracy: 0.9046\n","Epoch 600/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8121 - accuracy: 0.9800 - val_loss: 1.0452 - val_accuracy: 0.9030\n","Epoch 601/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8134 - accuracy: 0.9796 - val_loss: 1.0403 - val_accuracy: 0.9026\n","Epoch 602/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8149 - accuracy: 0.9792 - val_loss: 1.0518 - val_accuracy: 0.9006\n","Epoch 603/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8175 - accuracy: 0.9785 - val_loss: 1.0524 - val_accuracy: 0.9022\n","Epoch 604/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8103 - accuracy: 0.9802 - val_loss: 1.0449 - val_accuracy: 0.9028\n","Epoch 605/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8351 - accuracy: 0.9742 - val_loss: 1.0532 - val_accuracy: 0.9006\n","Epoch 606/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8704 - accuracy: 0.9678 - val_loss: 1.0381 - val_accuracy: 0.9044\n","Epoch 607/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8273 - accuracy: 0.9763 - val_loss: 1.0360 - val_accuracy: 0.9056\n","Epoch 608/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8051 - accuracy: 0.9805 - val_loss: 1.0457 - val_accuracy: 0.9034\n","Epoch 609/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8048 - accuracy: 0.9805 - val_loss: 1.0412 - val_accuracy: 0.9030\n","Epoch 610/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8047 - accuracy: 0.9805 - val_loss: 1.0436 - val_accuracy: 0.9026\n","Epoch 611/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8117 - accuracy: 0.9788 - val_loss: 1.0473 - val_accuracy: 0.9001\n","Epoch 612/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8007 - accuracy: 0.9811 - val_loss: 1.0403 - val_accuracy: 0.9034\n","Epoch 613/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8151 - accuracy: 0.9781 - val_loss: 1.0396 - val_accuracy: 0.9018\n","Epoch 614/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8030 - accuracy: 0.9811 - val_loss: 1.0447 - val_accuracy: 0.9022\n","Epoch 615/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8230 - accuracy: 0.9762 - val_loss: 1.0494 - val_accuracy: 0.9024\n","Epoch 616/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8106 - accuracy: 0.9786 - val_loss: 1.0436 - val_accuracy: 0.9024\n","Epoch 617/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8011 - accuracy: 0.9806 - val_loss: 1.0363 - val_accuracy: 0.9031\n","Epoch 618/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8002 - accuracy: 0.9807 - val_loss: 1.0418 - val_accuracy: 0.9029\n","Epoch 619/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8011 - accuracy: 0.9805 - val_loss: 1.0443 - val_accuracy: 0.9028\n","Epoch 620/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.8031 - accuracy: 0.9801 - val_loss: 1.0400 - val_accuracy: 0.9027\n","Epoch 621/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8025 - accuracy: 0.9803 - val_loss: 1.0446 - val_accuracy: 0.9029\n","Epoch 622/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8005 - accuracy: 0.9807 - val_loss: 1.0384 - val_accuracy: 0.9039\n","Epoch 623/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7975 - accuracy: 0.9811 - val_loss: 1.0365 - val_accuracy: 0.9032\n","Epoch 624/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.7988 - accuracy: 0.9806 - val_loss: 1.0381 - val_accuracy: 0.9021\n","Epoch 625/1000\n","656/656 [==============================] - 7s 10ms/step - loss: 0.7987 - accuracy: 0.9804 - val_loss: 1.0375 - val_accuracy: 0.9035\n","Epoch 626/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8066 - accuracy: 0.9787 - val_loss: 1.0484 - val_accuracy: 0.9010\n","Epoch 627/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8023 - accuracy: 0.9795 - val_loss: 1.0350 - val_accuracy: 0.9036\n","Epoch 628/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.7988 - accuracy: 0.9804 - val_loss: 1.0375 - val_accuracy: 0.9029\n","Epoch 629/1000\n","656/656 [==============================] - 6s 8ms/step - loss: 0.8043 - accuracy: 0.9788 - val_loss: 1.0511 - val_accuracy: 0.9027\n","Epoch 630/1000\n","656/656 [==============================] - 7s 11ms/step - loss: 0.7939 - accuracy: 0.9812 - val_loss: 1.0403 - val_accuracy: 0.9036\n","Epoch 631/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7942 - accuracy: 0.9813 - val_loss: 1.0379 - val_accuracy: 0.9029\n","Epoch 632/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7958 - accuracy: 0.9807 - val_loss: 1.0424 - val_accuracy: 0.9045\n","Epoch 633/1000\n","656/656 [==============================] - 6s 9ms/step - loss: 0.7955 - accuracy: 0.9811 - val_loss: 1.0417 - val_accuracy: 0.9037\n","Epoch 634/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7933 - accuracy: 0.9808 - val_loss: 1.0454 - val_accuracy: 0.9022\n","Epoch 635/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7925 - accuracy: 0.9810 - val_loss: 1.0423 - val_accuracy: 0.9030\n","Epoch 636/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7971 - accuracy: 0.9802 - val_loss: 1.0409 - val_accuracy: 0.9027\n","Epoch 637/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7945 - accuracy: 0.9802 - val_loss: 1.0372 - val_accuracy: 0.9032\n","Epoch 638/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7907 - accuracy: 0.9811 - val_loss: 1.0389 - val_accuracy: 0.9028\n","Epoch 639/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.8017 - accuracy: 0.9788 - val_loss: 1.0413 - val_accuracy: 0.9027\n","Epoch 640/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7915 - accuracy: 0.9813 - val_loss: 1.0468 - val_accuracy: 0.9026\n","Epoch 641/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7869 - accuracy: 0.9820 - val_loss: 1.0366 - val_accuracy: 0.9039\n","Epoch 642/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7896 - accuracy: 0.9814 - val_loss: 1.0366 - val_accuracy: 0.9032\n","Epoch 643/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7937 - accuracy: 0.9805 - val_loss: 1.0348 - val_accuracy: 0.9036\n","Epoch 644/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7897 - accuracy: 0.9811 - val_loss: 1.0385 - val_accuracy: 0.9026\n","Epoch 645/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7964 - accuracy: 0.9800 - val_loss: 1.0406 - val_accuracy: 0.9020\n","Epoch 646/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7881 - accuracy: 0.9814 - val_loss: 1.0394 - val_accuracy: 0.9028\n","Epoch 647/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7898 - accuracy: 0.9806 - val_loss: 1.0493 - val_accuracy: 0.9027\n","Epoch 648/1000\n","656/656 [==============================] - 6s 10ms/step - loss: 0.7884 - accuracy: 0.9812 - val_loss: 1.0459 - val_accuracy: 0.9027\n","Epoch 649/1000\n","328/656 [==============>...............] - ETA: 2s - loss: 0.7881 - accuracy: 0.9816"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-986658cfbaf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"x0Dry9DYnjmy"},"source":[""],"id":"x0Dry9DYnjmy","execution_count":null,"outputs":[]}]}